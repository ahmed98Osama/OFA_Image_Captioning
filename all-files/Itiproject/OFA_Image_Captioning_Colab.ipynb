{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jJOSpPHCX8z"
      },
      "source": [
        "# **OFA**\n",
        "Start to enjoy image captioning with OFA! "
      ],
      "id": "_jJOSpPHCX8z"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "l5_6cX2w5-0K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path = os.getcwd()\n",
        "os.chdir(path)"
      ],
      "id": "l5_6cX2w5-0K"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFip_qM0Zfaa",
        "outputId": "e332bc13-b14e-422e-e195-3906ecd54798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.7/dist-packages (5.1.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "!pip install -q streamlit\n",
        "!pip install pyngrok"
      ],
      "id": "sFip_qM0Zfaa"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "742c3304",
        "outputId": "2c560295-1b7e-4e59-cc0a-58f476cf76ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-12 21:17:54--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.237.133.81, 52.202.168.65, 18.205.222.128, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.237.133.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  19.0MB/s    in 0.7s    \n",
            "\n",
            "2022-08-12 21:17:55 (19.0 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ],
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "id": "742c3304"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njPs2wsQZfLA",
        "outputId": "0d7b40b7-ff49-4758-b58e-1b12eb832eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!./ngrok authtoken 2DGuJGYGshFG6l1eTCq9MBk3uRj_3NvGYT4SerJiG1r8K5GfR"
      ],
      "id": "njPs2wsQZfLA"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biZApdSoZcc-",
        "outputId": "5456907a-d439-466b-f57d-1113d2a0501b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://fe68-35-185-199-183.ngrok.io\" -> \"http://localhost:80\">"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from pyngrok import ngrok \n",
        "public_url = ngrok.connect(port='8501')\n",
        "public_url"
      ],
      "id": "biZApdSoZcc-"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOi2N_PMgQ7U",
        "outputId": "7da54fdc-e707-4d81-ef0c-4d7bf7284ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "%cd /content"
      ],
      "id": "HOi2N_PMgQ7U"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mE8hHnb4UBa",
        "outputId": "298f227b-bb9f-472e-ba28-4b471ee4c7e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OFA'...\n",
            "remote: Enumerating objects: 6056, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 6056 (delta 39), reused 64 (delta 23), pack-reused 5960\u001b[K\n",
            "Receiving objects: 100% (6056/6056), 122.11 MiB | 36.57 MiB/s, done.\n",
            "Resolving deltas: 100% (2307/2307), done.\n"
          ]
        }
      ],
      "source": [
        "# clone OFA if there does not exist the repo\n",
        "!git clone https://github.com/OFA-Sys/OFA.git"
      ],
      "id": "4mE8hHnb4UBa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dQmNjQdCt93"
      },
      "source": [
        "## **Download Checkpoint**\n",
        "We provide a link for our public checkpoint, and you only need to wget it to your workspace. We also provide an alternative below. Choose one as you like!"
      ],
      "id": "9dQmNjQdCt93"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5S238JJhvjrI",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "os.mkdir(path + \"/OFA/checkpoints/\")\n",
        "os.chdir(path + \"/OFA/checkpoints/\")"
      ],
      "id": "5S238JJhvjrI"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-kt6zTvAaGa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48295690-b075-47a6-c45b-40be4ba9d674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-12 21:34:35--  https://ofa-silicon.oss-us-west-1.aliyuncs.com/checkpoints/caption_large_best_clean.pt\n",
            "Resolving ofa-silicon.oss-us-west-1.aliyuncs.com (ofa-silicon.oss-us-west-1.aliyuncs.com)... 47.88.111.45\n",
            "Connecting to ofa-silicon.oss-us-west-1.aliyuncs.com (ofa-silicon.oss-us-west-1.aliyuncs.com)|47.88.111.45|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5717992325 (5.3G) [application/octet-stream]\n",
            "Saving to: ‘caption.pt’\n",
            "\n",
            "caption.pt          100%[===================>]   5.33G  16.9MB/s    in 5m 1s   \n",
            "\n",
            "2022-08-12 21:39:35 (18.1 MB/s) - ‘caption.pt’ saved [5717992325/5717992325]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#import wget\n",
        "\n",
        "#filename = wget.download('https://ofa-silicon.oss-us-west-1.aliyuncs.com/checkpoints/caption_large_best_clean.pt', out=\"caption.pt\")\n",
        "#filename\n",
        "\n",
        "! wget -O  caption.pt https://ofa-silicon.oss-us-west-1.aliyuncs.com/checkpoints/caption_large_best_clean.pt"
      ],
      "id": "-kt6zTvAaGa6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-BbNqgvDH4l"
      },
      "source": [
        "## **Install Fairseq**\n",
        "We advise you to install fairseq by cloning the official repository and running \"pip install\". \n",
        "\n",
        "You should restart the window if you meet the hint of \"RESTART RUNTIME\". "
      ],
      "id": "P-BbNqgvDH4l"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fp4uO91Y6Nrz",
        "outputId": "4193e70b-c08c-4bec-9054-a825925600ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 32167, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 32167 (delta 11), reused 6 (delta 1), pack-reused 32129\u001b[K\n",
            "Receiving objects: 100% (32167/32167), 22.55 MiB | 28.26 MiB/s, done.\n",
            "Resolving deltas: 100% (23569/23569), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2) (4.64.0)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2) (1.15.1)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 16.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2) (1.21.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2) (2022.6.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2) (0.29.32)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2) (0.12.1+cu113)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 20.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2) (5.9.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 21.1 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 22.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.1.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (4.9.1)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==0.12.2) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==0.12.2) (3.8.1)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp37-cp37m-linux_x86_64.whl size=15414890 sha256=8ec7006e914cd521447da2c699c0543d9003981c71623a6c2377acf8f8c01221\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x4zkzo3s/wheels/7c/35/80/edbd520a1a7e615df007002aeea9f6bf5f3c8f9243e072f6ce\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=c82d65ac8e705cb547cdfbc78535b049867a9b73f7b49a49d12f79434282aedd\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, portalocker, omegaconf, colorama, antlr4-python3-runtime, sacrebleu, hydra-core, bitarray, fairseq\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 bitarray-2.6.0 colorama-0.4.5 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.5.1 sacrebleu-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# clone Fairseq for installation\n",
        "os.chdir(path)\n",
        "! git clone https://github.com/pytorch/fairseq.git\n",
        "os.chdir(path + \"/fairseq\")\n",
        "! pip install --use-feature=in-tree-build ./"
      ],
      "id": "fp4uO91Y6Nrz"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LK8Iw1eP2bRb"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# path = os.getcwd()\n",
        "# os.chdir(path)\n",
        "# print(os.getcwd())\n",
        "\n",
        "# path = '/content'"
      ],
      "id": "LK8Iw1eP2bRb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUcWrcfgpyXN"
      },
      "source": [
        "Install GoogleTranslate"
      ],
      "id": "MUcWrcfgpyXN"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b02f9da4",
        "outputId": "18a1e74f-9929-42e2-a6f0-c3693909badb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting googletrans==4.0.0rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2022.6.15)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (3.0.4)\n",
            "Collecting hstspreload\n",
            "  Downloading hstspreload-2022.8.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 17.1 MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17416 sha256=3da53bf271dd7c66db756b96457d4e466d01e8928f9b4ba22bf238e3f44fc8d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/34/00/4fe71786ea6d12314b29037620c36d857e5d104ac2748bf82a\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hyperframe, hpack, sniffio, h2, h11, rfc3986, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2022.8.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gTTs\n",
            "  Downloading gTTS-2.2.4-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gTTs) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gTTs) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from gTTs) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gTTs) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gTTs) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gTTs) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gTTs) (1.24.3)\n",
            "Installing collected packages: gTTs\n",
            "Successfully installed gTTs-2.2.4\n"
          ]
        }
      ],
      "source": [
        "! pip install googletrans==4.0.0rc1\n",
        "! pip install gTTs"
      ],
      "id": "b02f9da4"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nEmI6ATppxRG"
      },
      "outputs": [],
      "source": [
        "from googletrans import Translator\n",
        "from gtts import gTTS"
      ],
      "id": "nEmI6ATppxRG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P54XzUU_FK1_"
      },
      "source": [
        "## **Preparation**\n",
        "Below you just need to import required packages, and check whether to use GPU or FP16. "
      ],
      "id": "P54XzUU_FK1_"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzbFZ1ftE6Z5",
        "outputId": "a1f2998b-8672-4cd7-f8b1-7f68c2f53c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/OFA\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
            "\u001b[K     |████████████████████████████████| 509 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.6.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ftfy==6.0.3\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy==6.0.3) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=f22d4c88b44f6c4c304a183c5d437522b174117070644d3569cc39fa817d0e47\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.0.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX==2.4.1\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.4.1) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.4.1) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX==2.4.1) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycocotools==2.0.4 in /usr/local/lib/python3.7/dist-packages (2.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0.4) (1.21.6)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0.4) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.4) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.4) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.4) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.4) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools==2.0.4) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0.4) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycocoevalcap==1.2\n",
            "  Downloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 104.3 MB 77 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from pycocoevalcap==1.2) (2.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->pycocoevalcap==1.2) (1.21.6)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->pycocoevalcap==1.2) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (1.15.0)\n",
            "Installing collected packages: pycocoevalcap\n",
            "Successfully installed pycocoevalcap-1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.7.1-py3-none-any.whl (701 kB)\n",
            "\u001b[K     |████████████████████████████████| 701 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 57.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.1.1)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 72.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.12.1+cu113)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n",
            "Collecting tensorboard>=2.9.1\n",
            "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 58.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Collecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.47.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning) (3.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (0.13.0)\n",
            "Installing collected packages: fsspec, torchmetrics, tensorboard, pyDeprecate, pytorch-lightning\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.10.0 which is incompatible.\u001b[0m\n",
            "Successfully installed fsspec-2022.7.1 pyDeprecate-0.3.2 pytorch-lightning-1.7.1 tensorboard-2.10.0 torchmetrics-0.9.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[K     |████████████████████████████████| 365 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 67.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 14.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 60.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 68.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.15.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\u001b[0m\n",
            "Successfully installed datasets-2.4.0 huggingface-hub-0.8.1 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.6)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (4.64.0)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=ae360cf0986975f8b8b924dadb818c9d0593b679186512df5c3094a828117102\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ac/6b/38096e3c5bf1dc87911e3585875e21a3ac610348e740409c76\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "os.chdir(path + \"/OFA\")\n",
        "print(os.getcwd())\n",
        "! sed '1d' requirements.txt | xargs -I {} pip install {}"
      ],
      "id": "wzbFZ1ftE6Z5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5gToRpjGqUa"
      },
      "source": [
        "## **Preprocess**\n",
        "We demonstrate the required transformation fucntions for preprocessing inputs."
      ],
      "id": "X5gToRpjGqUa"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geKevFz94TaY",
        "outputId": "85d91d64-5579-4b14-f847-2739522f501c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing streamlity_app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile streamlity_app.py \n",
        "import streamlit as st \n",
        "from PIL import Image\n",
        "import io\n",
        "from googletrans import Translator\n",
        "from gtts import gTTS\n",
        "import torch\n",
        "import wget\n",
        "import numpy as np\n",
        "from models.ofa import OFAModel\n",
        "from PIL import Image\n",
        "from fairseq import utils,tasks\n",
        "from fairseq import checkpoint_utils\n",
        "from utils.eval_utils import eval_step\n",
        "from tasks.mm_tasks.caption import CaptionTask\n",
        "from torchvision import transforms\n",
        "\n",
        "#############################################################################################\n",
        "@st.cache(suppress_st_warning=True , allow_output_mutation=True)\n",
        "def load_model():\n",
        "    \n",
        "    #filename = wget.download('https://ofa-silicon.oss-us-west-1.aliyuncs.com/checkpoints/caption_large_best_clean.pt', out=\"checkpoints/caption.pt\")\n",
        "    \n",
        "    # Register caption task\n",
        "    tasks.register_task('caption',CaptionTask)\n",
        "\n",
        "    # turn on cuda if GPU is available\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    # use fp16 only when GPU is available\n",
        "    use_fp16 = False\n",
        "\n",
        "\n",
        "    # Load pretrained ckpt & config\n",
        "    overrides={\"bpe_dir\":\"utils/BPE\", \"eval_cider\":False, \"beam\":5, \"max_len_b\":16, \"no_repeat_ngram_size\":3, \"seed\":7}\n",
        "    models, cfg, task = checkpoint_utils.load_model_ensemble_and_task(\n",
        "            utils.split_paths('checkpoints/caption.pt'),\n",
        "            arg_overrides=overrides\n",
        "        )\n",
        "\n",
        "    # Move models to GPU\n",
        "    for model in models:\n",
        "        model.eval()\n",
        "        if use_fp16:\n",
        "            model.half()\n",
        "        if use_cuda and not cfg.distributed_training.pipeline_model_parallel:\n",
        "            model.cuda()\n",
        "        model.prepare_for_inference_(cfg)\n",
        "\n",
        "    # Initialize generator\n",
        "    generator = task.build_generator(models, cfg.generation)\n",
        "\n",
        "    return task, generator, models, cfg, use_cuda, use_fp16\n",
        "\n",
        "\n",
        "def transform_image(cfg,task):\n",
        "    # Image transform\n",
        "    mean = [0.5, 0.5, 0.5]\n",
        "    std = [0.5, 0.5, 0.5]\n",
        "\n",
        "    patch_resize_transform = transforms.Compose([\n",
        "        lambda image: image.convert(\"RGB\"),\n",
        "        transforms.Resize((cfg.task.patch_image_size, cfg.task.patch_image_size), interpolation=Image.BICUBIC),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std),\n",
        "    ])\n",
        "\n",
        "    return patch_resize_transform\n",
        "\n",
        "\n",
        "def encode_text(text, task, length=None, append_bos=False, append_eos=False):\n",
        "    # Text preprocess\n",
        "    bos_item = torch.LongTensor([task.src_dict.bos()])\n",
        "    eos_item = torch.LongTensor([task.src_dict.eos()])\n",
        "    # task\n",
        "    s = task.tgt_dict.encode_line(\n",
        "        line=task.bpe.encode(text),\n",
        "        add_if_not_exist=False,\n",
        "        append_eos=False\n",
        "    ).long()\n",
        "    if length is not None:\n",
        "        s = s[:length]\n",
        "    if append_bos:\n",
        "        s = torch.cat([bos_item, s])\n",
        "    if append_eos:\n",
        "        s = torch.cat([s, eos_item])\n",
        "    \n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "\n",
        "# Construct input for caption task\n",
        "def construct_sample(patch_resize_transform, task, image: Image):\n",
        "    # patch_resize_transform , encode_text --> task\n",
        "    patch_image = patch_resize_transform(image).unsqueeze(0)\n",
        "    patch_mask = torch.tensor([True])\n",
        "    src_text = encode_text(\" what does the image describe?\", task,append_bos=True, append_eos=True).unsqueeze(0)\n",
        "    # text preprocess\n",
        "    pad_idx = task.src_dict.pad()\n",
        "    src_length = torch.LongTensor([s.ne(pad_idx).long().sum() for s in src_text])\n",
        "    sample = {\n",
        "        \"id\":np.array(['42']),\n",
        "        \"net_input\": {\n",
        "            \"src_tokens\": src_text,\n",
        "            \"src_lengths\": src_length,\n",
        "            \"patch_images\": patch_image,\n",
        "            \"patch_masks\": patch_mask\n",
        "        }\n",
        "    }\n",
        "    return sample\n",
        "  \n",
        "# Function to turn FP32 to FP16\n",
        "def apply_half(t):\n",
        "    if t.dtype is torch.float32:\n",
        "        return t.to(dtype=torch.half)\n",
        "    return t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################################################################################\n",
        "\n",
        "def get_Caption(image, use_cuda, use_fp16, task, generator, models, patch_resize_transform):\n",
        "    # use_cuda , use_fp16 , task, generator, models\n",
        "    # Construct input sample & preprocess for GPU if cuda available\n",
        "    sample = construct_sample(patch_resize_transform, task, image)\n",
        "    sample = utils.move_to_cuda(sample) if use_cuda else sample\n",
        "    sample = utils.apply_to_sample(apply_half, sample) if use_fp16 else sample\n",
        "    # Run eval step for caption\n",
        "    with torch.no_grad():\n",
        "        result, scores = eval_step(task, generator, models, sample)\n",
        "\n",
        "    caption = result[0]['caption']\n",
        "    return caption\n",
        "\n",
        "\n",
        "def load_image():\n",
        "    uploaded_file = st.file_uploader(label='Pick an image to test')\n",
        "    if uploaded_file is not None:\n",
        "        image_data = uploaded_file.getvalue()\n",
        "        st.image(image_data)\n",
        "        return Image.open(io.BytesIO(image_data))\n",
        "    else:\n",
        "        return None\n",
        "#         st.image('/home/ubuntu/content/test/test_img.png')\n",
        "#         return Image.open('/home/ubuntu/content/test/test_img.png')\n",
        "\n",
        "\n",
        "def text_to_speech(caption):   \n",
        "    audio_english = gTTS(text=caption, lang='en', slow=False)\n",
        "    en_file_name = \"enAudio\" \n",
        "    audio_english.save(f\"{en_file_name}.mp3\")\n",
        "    translator = Translator()\n",
        "    #translate text\n",
        "    translated_text = translator.translate(caption, src='en', dest = 'ar').text\n",
        "    \n",
        "    audio_arabic = gTTS(text=translated_text, lang='ar', slow=False)\n",
        "    ar_file_name = \"arAudio\"\n",
        "    audio_arabic.save(f\"{ar_file_name}.mp3\")\n",
        "    return translated_text, en_file_name, ar_file_name\n",
        "    \n",
        "\n",
        "\n",
        "def main():\n",
        "    st.title('Image Caption Generator')\n",
        "    #image_path = '/home/ubuntu/content/test/test_img.png'\n",
        "    task, generator, models, cfg, use_cuda, use_fp16 = load_model()\n",
        "    patch_resize_transform = transform_image(cfg,task)\n",
        "    image_path = load_image()\n",
        "    if (image_path != None) : \n",
        "        caption = get_Caption(image_path, use_cuda, use_fp16, task, generator,\n",
        "                              models, patch_resize_transform)\n",
        "\n",
        "        result_btn = st.button('Generate Caption & Audio')\n",
        "        if result_btn:\n",
        "            st.write('Generating Caption...')\n",
        "            st.write(caption)\n",
        "\n",
        "            st.write('Generating Audio...')\n",
        "            ar_text, en_file_name, ar_file_name = text_to_speech(caption)\n",
        "\n",
        "            #english\n",
        "            audio_file_en = open(f\"{en_file_name}.mp3\", \"rb\")\n",
        "            audio_bytes_en = audio_file_en.read()\n",
        "            st.markdown(f\"## English audio:\")\n",
        "            st.audio(audio_bytes_en, format=\"audio/mp3\", start_time=0)\n",
        "\n",
        "            st.write('Arabic Translated Caption:')\n",
        "            st.write(ar_text)\n",
        "            #arabic\n",
        "            audio_file_ar = open(f\"{ar_file_name}.mp3\", \"rb\")\n",
        "            audio_bytes_ar = audio_file_ar.read()\n",
        "            st.markdown(f\"## Arabic audio:\")\n",
        "            st.audio(audio_bytes_ar, format=\"audio/mp3\", start_time=0)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "id": "geKevFz94TaY"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYb5tsQ34xou",
        "outputId": "cff76f16-6a99-4369-eab7-7b2d1be44051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-12 21:42:31.592 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.185.199.183:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.031s\n",
            "your url is: https://witty-moons-arrive-35-185-199-183.loca.lt\n",
            "2022-08-12 22:14:27.838 Created a temporary directory at /tmp/tmpap3yordu\n",
            "2022-08-12 22:14:27.838 Writing /tmp/tmpap3yordu/_remote_module_non_scriptable.py\n",
            "2022-08-12 22:14:52.291 source dictionary: 59457 types\n",
            "2022-08-12 22:14:52.291 target dictionary: 59457 types\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n",
            "/content/OFA/models/sequence_generator.py:698: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = bbsz_idx // beam_size\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n",
            "/content/OFA/models/sequence_generator.py:698: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = bbsz_idx // beam_size\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n",
            "/content/OFA/models/sequence_generator.py:698: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = bbsz_idx // beam_size\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n",
            "/content/OFA/models/sequence_generator.py:698: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = bbsz_idx // beam_size\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n",
            "/content/OFA/models/sequence_generator.py:698: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = bbsz_idx // beam_size\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n",
            "/content/OFA/models/sequence_generator.py:698: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = bbsz_idx // beam_size\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n",
            "/content/OFA/models/sequence_generator.py:698: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = bbsz_idx // beam_size\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n",
            "/content/OFA/models/sequence_generator.py:698: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = bbsz_idx // beam_size\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n",
            "/content/OFA/models/sequence_generator.py:698: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = bbsz_idx // beam_size\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n",
            "/content/OFA/models/sequence_generator.py:698: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = bbsz_idx // beam_size\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run streamlity_app.py & npx localtunnel -p 8501"
      ],
      "id": "jYb5tsQ34xou"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "OFA_Image_Captioning_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Environment (conda_anaconda3)",
      "language": "python",
      "name": "conda_anaconda3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}